{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 >= 0\n",
      "1 > 0\n",
      "0 > 0\n",
      "0 == 0\n",
      "1 == 1\n",
      "0 == 0\n",
      "1 == 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "os.environ[\"TRITON_INTERPRET\"] = '0' # Need to set before importing Triton\n",
    "\n",
    "def check_tensors_gpu_ready(*tensors: torch.Tensor):\n",
    "    for t in tensors:\n",
    "        assert t.is_contiguous(), \"A tensor is not contiguous\"\n",
    "        if not os.environ.get('TRITON_INTERPRET') == '1':\n",
    "            assert t.is_cuda, \"A tensor is not on GPU\"\n",
    "\n",
    "def test_pid_conds(conds_str: str, pid_0=[0], pid_1=[0], pid_2=[0]) -> bool:\n",
    "    pids = pid_0[0], pid_1[0], pid_2[0]\n",
    "    conds = conds_str.replace(' ', '').split(',')\n",
    "    for i, (cond, pid) in enumerate(zip(conds, pids)):\n",
    "        if cond == \"\":\n",
    "            continue\n",
    "        try:\n",
    "            op, threshold = cond[0], int(cond[1:])\n",
    "        except ValueError as e:\n",
    "            if len(cond[1:]) == 2:\n",
    "                op, threshold = cond[0:2], int(cond[2:])\n",
    "            else:\n",
    "                raise ValueError(e)\n",
    "        if op not in ['<','>','>=','<=','=', '!=']: \n",
    "            raise ValueError(f\"Rules may only use these ops: '<','>','>=','<=','=', '!='. Invalid rule: '{cond}'.\")\n",
    "        op = \"==\" if op == \"=\" else op\n",
    "        if not eval(f\"{pid} {op} {threshold}\"):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "assert test_pid_conds(\"\")\n",
    "assert test_pid_conds(\">=0\")\n",
    "assert test_pid_conds(\">0\", [1], [1])\n",
    "assert not test_pid_conds(\">0\", [0], [1])\n",
    "assert test_pid_conds(\"=0,=1\", [0], [1], [1])\n",
    "assert test_pid_conds(\"=0, =1\", [0], [1], [2])\n",
    "\n",
    "def breakpoint_if(conds: str, pid_0=[0], pid_1=[0], pid_2=[0]):\n",
    "    if test_pid_conds(conds, pid_0, pid_1, pid_2):\n",
    "        set_trace()\n",
    "\n",
    "def print_if(txt: str, conds: str, pid_0=[0], pid_1=[0], pid_2=[0]):\n",
    "    if test_pid_conds(conds, pid_0, pid_1, pid_2):\n",
    "        print(txt)\n",
    "\n",
    "def cdiv(a: int, b: int):\n",
    "    return (a + b - 1) // b\n",
    "\n",
    "assert cdiv(10, 2) == 5\n",
    "assert cdiv(11, 2) == 6\n",
    "\n",
    "check_tensors_gpu_ready(torch.tensor([1, 2, 3], device=\"cuda\"), torch.tensor([[4, 5, 6], [7 ,8, 9], [10, 11, 12]], device=\"cuda\")[:, 2].contiguous())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notiredt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
